{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c4e4193",
   "metadata": {},
   "source": [
    "Lectura de los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d0f447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def extraer_imagenes(directorio=r'/home/cursos/ima543_2025_1/ima543_share/Datasets/FER/test'):\n",
    "    \"\"\"\n",
    "    Carga todas las imágenes desde el directorio especificado, normaliza las imágenes y devuelve las matrices listas para entrenamiento o prueba.\n",
    "    \"\"\"\n",
    "    clases = []\n",
    "    imagenes = []\n",
    "    lista_carpetas = os.listdir(directorio)\n",
    "    \n",
    "    k = 0\n",
    "    for carpeta_clase in lista_carpetas:\n",
    "        ruta_carpeta = os.path.join(directorio, carpeta_clase)\n",
    "        if not os.path.isdir(ruta_carpeta):\n",
    "            continue  # Ignorar si no es carpeta\n",
    "        fotos = os.listdir(ruta_carpeta)\n",
    "        for foto in fotos:\n",
    "            img_path = os.path.join(ruta_carpeta, foto)\n",
    "            imagen = image.load_img(img_path, target_size=(256, 256))\n",
    "            imagenes.append(np.array(imagen))\n",
    "            clases.append(k)\n",
    "        k += 1\n",
    "\n",
    "    # Conversión a numpy\n",
    "    X = np.array(imagenes, dtype=np.float32)\n",
    "    y = np.array(clases)\n",
    "\n",
    "    # Formato\n",
    "    image_size = X.shape[1]\n",
    "    X = np.reshape(X, [-1, image_size, image_size, 3])\n",
    "\n",
    "    # Normalizar\n",
    "    X = X / 255.0\n",
    "\n",
    "    # One-hot encoding\n",
    "    y = to_categorical(y)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f354c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos de entrenamiento\n",
    "X_train, y_train = extraer_imagenes(\n",
    "    directorio=r'/home/cursos/ima543_2025_1/ima543_share/Datasets/FER/train'\n",
    ")\n",
    "\n",
    "# Cargar datos de prueba\n",
    "X_test, y_test = extraer_imagenes(\n",
    "    directorio=r'/home/cursos/ima543_2025_1/ima543_share/Datasets/FER/test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f682344",
   "metadata": {},
   "source": [
    "Procesando data en DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e07aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Trains a 100-Layer DenseNet on tus datos personalizados.\"\"\"\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Input, Flatten, Dropout\n",
    "from tensorflow.keras.layers import concatenate, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Importa aquí tu función (defínela antes o en un módulo aparte)\n",
    "from extraer_imagenes import extraer_imagenes\n",
    "\n",
    "# --- Parámetros de entrenamiento ---\n",
    "batch_size = 32\n",
    "#epochs = 200\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "\n",
    "# --- Parámetros de la red ---\n",
    "# Growth rate | Depth   |  Accuracy (paper) ...\n",
    "growth_rate = 12\n",
    "depth = 100\n",
    "num_dense_blocks = 4\n",
    "use_max_pool = False\n",
    "\n",
    "num_bottleneck_layers = (depth - 4) // (2 * num_dense_blocks)\n",
    "num_filters_bef_dense_block = 2 * growth_rate\n",
    "compression_factor = 0.5\n",
    "\n",
    "# --- Carga tus datos desde carpetas Train / Test ---\n",
    "train_dir = r'/home/cursos/ima543_2025_1/ima543_share/Datasets/FER/train'\n",
    "test_dir  = r'/home/cursos/ima543_2025_1/ima543_share/Datasets/FER/test'\n",
    "\n",
    "x_train, y_train = extraer_imagenes(directorio=train_dir)\n",
    "x_test,  y_test  = extraer_imagenes(directorio=test_dir)\n",
    "\n",
    "# Número de clases y forma de entrada\n",
    "num_classes = y_train.shape[1]\n",
    "input_shape = x_train.shape[1:]  # e.g. (256, 256, 3)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# --- Definición de la función de LR schedule (queda igual) ---\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print(f'Epoch {epoch} — Learning rate: {lr}')\n",
    "    return lr\n",
    "\n",
    "# (Aquí seguiría la construcción de tu modelo DenseNet, \n",
    "# los callbacks, el compilado y el fit con ImageDataGenerator si lo usas.)\n",
    "\n",
    "# Ejemplo de fit con data augmentation:\n",
    "if data_augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "    )\n",
    "    datagen.fit(x_train)\n",
    "    model.fit(\n",
    "        datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "        validation_data=(x_test, y_test),\n",
    "        epochs=epochs,\n",
    "        callbacks=[\n",
    "            LearningRateScheduler(lr_schedule),\n",
    "            ModelCheckpoint(...),\n",
    "            ReduceLROnPlateau(...)\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, y_test),\n",
    "        epochs=epochs,\n",
    "        callbacks=[LearningRateScheduler(lr_schedule)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bottleneck_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17461240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start model definition\n",
    "# densenet CNNs (composite function) are made of BN-ReLU-Conv2D\n",
    "inputs = Input(shape=input_shape)\n",
    "x = BatchNormalization()(inputs)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(num_filters_bef_dense_block,kernel_size=3,padding='same',kernel_initializer='he_normal')(x)\n",
    "x = concatenate([inputs, x])\n",
    "\n",
    "# stack of dense blocks bridged by transition layers\n",
    "for i in range(num_dense_blocks):\n",
    "    # a dense block is a stack of bottleneck layers\n",
    "    for j in range(num_bottleneck_layers):\n",
    "        y = BatchNormalization()(x)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Conv2D(4 * growth_rate,kernel_size=1,padding='same',kernel_initializer='he_normal')(y)\n",
    "        if not data_augmentation:\n",
    "            y = Dropout(0.2)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Activation('relu')(y)\n",
    "        y = Conv2D(growth_rate,kernel_size=3,padding='same',kernel_initializer='he_normal')(y)\n",
    "        if not data_augmentation:\n",
    "            y = Dropout(0.2)(y)\n",
    "        x = concatenate([x, y])\n",
    "\n",
    "    # no transition layer after the last dense block\n",
    "    if i == num_dense_blocks - 1:\n",
    "        continue\n",
    "\n",
    "    # transition layer compresses num of feature maps and reduces the size by 2\n",
    "    num_filters_bef_dense_block += num_bottleneck_layers * growth_rate\n",
    "    num_filters_bef_dense_block = int(num_filters_bef_dense_block * compression_factor)\n",
    "    y = BatchNormalization()(x)\n",
    "    y = Conv2D(num_filters_bef_dense_block,kernel_size=1,padding='same',kernel_initializer='he_normal')(y)\n",
    "    if not data_augmentation:\n",
    "        y = Dropout(0.2)(y)\n",
    "    x = AveragePooling2D()(y)\n",
    "\n",
    "\n",
    "# add classifier on top\n",
    "# after average pooling, size of feature map is 1 x 1\n",
    "x = AveragePooling2D(pool_size=4)(x)\n",
    "y = Flatten()(x)\n",
    "outputs = Dense(num_classes,kernel_initializer='he_normal',activation='softmax')(y)\n",
    "\n",
    "# instantiate and compile model\n",
    "# orig paper uses SGD but RMSprop works better for DenseNet\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(1e-3),metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ebfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model model saving directory\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models_'+ str(epochs) +'_epocas')\n",
    "model_name = 'cifar10_densenet_model.{epoch:02d}.h5'\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# prepare callbacks for model saving and for learning rate reducer\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,monitor='val_acc',verbose=2,save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),cooldown=0,patience=5,min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "import time\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "# run training, with or without data augmentation\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,\n",
    "              validation_data=(x_test, y_test),shuffle=True,callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # preprocessing  and realtime data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (deg 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally\n",
    "        height_shift_range=0.1,  # randomly shift images vertically\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    steps_per_epoch = math.ceil(len(x_train) / batch_size)\n",
    "    # fit the model on the batches generated by datagen.flow().\n",
    "    model.fit(x=datagen.flow(x_train, y_train, batch_size=batch_size),verbose=2,epochs=epochs,\n",
    "              validation_data=(x_test, y_test),steps_per_epoch=steps_per_epoch,callbacks=callbacks)\n",
    "\n",
    "fin=time.time()\n",
    "print('(RUNNING TIME: ' + str(fin-start) )\n",
    "# score trained model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9265de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gráfico de pérdida (loss)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history[\"loss\"], label=\"Pérdida Entrenamiento (2 entradas)\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Pérdida Validación (2 entradas)\")\n",
    "plt.title(\"Pérdida durante el entrenamiento\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Pérdida\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.savefig(\"pérdida_RNN.jpg\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de precisión (accuracy)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Precisión Entrenamiento (2 entradas)\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Precisión Validación (2 entradas)\")\n",
    "plt.title(\"Precisión durante el entrenamiento\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.savefig(\"precisión_RNN.jpg\", bbox_inches=\"tight\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ima357_2024_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
